{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SAT Words in Context question generation using Strands Agent framework and OpenAI model\n",
    "\n",
    "## Overview\n",
    "\n",
    "My first [attempt](https://github.com/PragyanR/GenAI_for_SAT_Prep) to create words in context type question using Llama 3B on A100 was a bit involved from a coding perspective. With the advent of Agentic AI, I was able to generate such questions under 50 lines of code and a prompt template.\n",
    "\n",
    "Strands Agentic framework made it very simple to try out the use case.\n",
    "\n",
    "Check out my site if you want to try out Words in Context questions that I generate: [Acesat.ai](https://www.acesat.ai/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and prerequisites\n",
    "\n",
    "### Prerequisites\n",
    "* Python 3.10+\n",
    "* gpt-4.1-mini access\n",
    "\n",
    "Let's now install the requirement packages for our Strands Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pre-requisites\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependency packages\n",
    "\n",
    "Now let's import the dependency packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from strands import Agent, tool\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up OpenAI keys\n",
    "\n",
    "Let's now setup the OpenAI API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your OpenAI key goes here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up custom tools\n",
    "\n",
    "I created three tools for the agent to call:\n",
    "\n",
    "first, check_word_exists, a tool for the agent to check if a word was to create a words in context question already. \n",
    "\n",
    "second, store_paragraph, a tool for the agent to call for storing the generated paragraph. \n",
    "\n",
    "third, store_answer_choices, a tool for the agent to call for storing the answer choices and the definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for storing words in context questions\n",
    "para = {}\n",
    "\n",
    "@tool\n",
    "def check_word_exists(word: str):\n",
    "    '''Check if a word was used already\n",
    "    Args:\n",
    "        word: a SAT word\n",
    "    '''\n",
    "    if word in para:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "@tool\n",
    "def store_paragraph(word: str, paragraph: str):\n",
    "    '''Store paragraph in the dictionary, para\n",
    "    Args:\n",
    "        word: a SAT word\n",
    "        paragraph: paragraph that was generated by the agent\n",
    "    '''\n",
    "    para[word] = {\"word\": word}\n",
    "    paragraph = paragraph.replace(word,\"__________________\")\n",
    "    para[word][\"question\"] = paragraph\n",
    "    para[word][\"ans_choices\"] = []\n",
    "    para[word][\"ans_choices_with_def\"] = {}\n",
    "\n",
    "@tool\n",
    "def store_answer_choice(choice: str, meaning: str, word: str):\n",
    "    '''Store answer choices\n",
    "    Args:\n",
    "        choice: answer choice\n",
    "        meaning: answer choice definition/meaning\n",
    "        word: a SAT word\n",
    "    '''\n",
    "    if choice not in para[word][\"ans_choices\"]:\n",
    "        para[word][\"ans_choices\"].append(choice)\n",
    "        \n",
    "    if choice not in para[word][\"ans_choices_with_def\"]:\n",
    "        para[word][\"ans_choices_with_def\"][choice] = meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM model\n",
    "\n",
    "Agent will leverage `gpt-4.1-mini` using LiteLLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1-mini\"\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=model, params={\"max_tokens\": 32000, \"temperature\": 0.7}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Words in Context questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prompt template for generating words in context question\n",
    "prompt = '''\n",
    "Always use chain of thought prompting.\n",
    "1)come up with a medium difficult SAT vocab word. This is the word that will be used to create a question\n",
    "2)come up with a best genre that fits the word better.\n",
    "3)check if word exists already, if yes, start again\n",
    "4)generate a 75-word paragraph on the genre with the word without describing how you came up with the genre. The word should be used only once in the paragraph.\n",
    "5)after generating, check if the word is used properly or not. if not, generate a new paragraph\n",
    "6)after generating, check if the word used more than once, generate a new paragraph\n",
    "7)store just the paragraph and nothing else.\n",
    "8)then get 3 words in comma seperated format: a difficult antonym of the word. The other two difficult words that does not have a similar meaning to the word.\n",
    "9)add the word to the comma separated list\n",
    "10)get meaning for each answer choice and store the answer choice with meaning\n",
    "'''\n",
    "# Function for generating \n",
    "def generate_question(prompt):\n",
    "    system_prompt = \"You are a simple agent that can generate a paragraph for a given word\"\n",
    "    agent = Agent(\n",
    "        model=litellm_model,\n",
    "        system_prompt=system_prompt,\n",
    "        tools=[store_paragraph, store_answer_choice, check_word_exists],\n",
    "    )\n",
    "    agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's start with step 1: coming up with a medium difficult SAT vocab word. A good word would be \"prosaic.\"\n",
      "\n",
      " fits the word \"prosaic\" would be a literary or descriptive genre, since \"prosaic\" refers to something that is commonplace or dull, often used to describe writing or expression.\n",
      "\n",
      "Step 3: I will check if the word \"prosaic\" exists already.\n",
      "Tool #1: check_word_exists\n",
      "The word \"prosaic\" does not exist already. Now, for step 4, I will generate a 75-word paragraph on the literary genre using the word \"prosaic\" only once.\n",
      "Tool #2: store_paragraph\n",
      "The paragraph was generated using the word \"prosaic\" once, and it appears to be used properly in context. Now, moving to step 8: I will get 3 words in comma-separated format: a difficult antonym of \"prosaic,\" and two other difficult words that are not similar in meaning to \"prosaic,\" plus add the word \"prosaic\" itself to the list. Then, I will get the meanings for each answer choice and store them.\n",
      "Tool #3: store_answer_choice\n",
      "\n",
      "Tool #4: store_answer_choice\n",
      "\n",
      "Tool #5: store_answer_choice\n",
      "\n",
      "Tool #6: store_answer_choice\n",
      "The SAT vocab word chosen is \"prosaic,\" and a paragraph using this word in a literary genre context has been generated and stored.\n",
      "\n",
      "The answer choices are:\n",
      " Commonplace or dull; lacking in imagination.\n",
      " usual or ordinary. (antonym) or remarkable; beyond what is\n",
      "- abstruse: Difficult to understand; obscure.\n",
      "fuscate: To deliberately make something unclear or difficult to understand.\n",
      "\n",
      " to do?prosaicing else you would like\n"
     ]
    }
   ],
   "source": [
    "# Specify number of questions to be generated\n",
    "question_count = 1\n",
    "for i in range(question_count):\n",
    "    generate_question(prompt)\n",
    "    for key in para:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"word\": \"prosaic\", \"question\": \"In the world of literature, some narratives captivate us with extraordinary events and vivid imagery, while others remain grounded in the __________________ details of everyday life. These straightforward stories, though lacking in dramatic flair, often reveal the subtle beauty and complexity within ordinary experiences. By focusing on the mundane, writers can highlight the universal truths that resonate deeply with readers, proving that even the simplest tales can hold profound meaning and emotional impact.\", \"ans_choices\": [\"extraordinary\", \"abstruse\", \"obfuscate\", \"prosaic\"], \"ans_choices_with_def\": {\"extraordinary\": \"Very unusual or remarkable; beyond what is usual or ordinary.\", \"abstruse\": \"Difficult to understand; obscure.\", \"obfuscate\": \"To deliberately make something unclear or difficult to understand.\", \"prosaic\": \"Commonplace or dull; lacking in imagination.\"}}\n"
     ]
    }
   ],
   "source": [
    "for key in para:\n",
    "    print(json.dumps(para[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the questions to a Json lines file\n",
    "with open(\"output.jsonl\", \"w\") as f:\n",
    "    for key in para:\n",
    "        print(key)\n",
    "        f.write(json.dumps(para[key])+ \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
